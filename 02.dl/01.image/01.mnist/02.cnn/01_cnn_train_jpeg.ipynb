{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Deep JPEG classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow is a library for numerical computation,\n",
    "here we build a deep convolutional MNIST classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "datapath = '/media/sf_as_d/repos/startupml/fitroom/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def encode_1h(x):\n",
    "    encoding = np.zeros((2))\n",
    "    encoding[x] = 1\n",
    "    return encoding\n",
    "\n",
    "def decode_1h(encoding):\n",
    "    return np.argmax(encoding)\n",
    "\n",
    "def flatten_image(image):\n",
    "    a = np.asarray(image)\n",
    "    rows, cols, channels = a.shape\n",
    "    length = rows * cols * channels \n",
    "    return a.reshape((1, length)), length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def get_filenames(path, pattern):\n",
    "    filenames = []\n",
    "    for f in os.listdir(path):\n",
    "        if re.search(pattern, f):\n",
    "            filenames.append(f)\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "\n",
    "def get_image(filepath):\n",
    "    \"\"\"\n",
    "    Image can be in gif jpeg or png format.\n",
    "    \"\"\"\n",
    "    with Image.open(filepath) as im:\n",
    "        flatten, _ = flatten_image(im)\n",
    "    return flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_images(datapath, pattern, batch_size, start, images):\n",
    "    num = 0\n",
    "\n",
    "    for fn in get_filenames(datapath, pattern):\n",
    "        num = num +1\n",
    "        if num > start:\n",
    "            if num > start+batch_size:\n",
    "                break\n",
    "            images.append(get_image(datapath+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_data_sets(datapath):\n",
    "    \"\"\"\n",
    "    Reads the jpeg images and returns train and test datasets labeled as one_hot\n",
    "    \"\"\"\n",
    "    image_train = []\n",
    "    image_test = []\n",
    "    label_train = []\n",
    "    label_test = []\n",
    "    \n",
    "    pattern = '^.*\\.[JPG|jpg]'\n",
    "    categories = ['Bra', 'Dress']\n",
    "    train_size = 100\n",
    "    test_size = 100\n",
    "\n",
    "    for l, c in enumerate(categories):\n",
    "        path = datapath + c + '/'\n",
    "        \n",
    "        get_images(path, pattern, train_size, 0, image_train)\n",
    "        label_train = label_train + [encode_1h(l) for _ in range(train_size)]\n",
    "        \n",
    "        get_images(path, pattern, test_size, train_size, image_test)\n",
    "        label_test = label_test + [encode_1h(l) for _ in range(test_size)]\n",
    "    \n",
    "    return image_train, label_train, image_test, label_test, categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mnist class stores the training, validation, and testing sets as NumPy arrays. It also provides a function for iterating through data minibatches, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_train, label_train, image_test, label_test, cats = read_data_sets(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 478500)\n",
      "Image size: 520500\n",
      "(20, 520500)\n"
     ]
    }
   ],
   "source": [
    "def create_tensor(images):\n",
    "    print images[0].shape\n",
    "    img_len = images[0].shape[1]\n",
    "    print 'Image size:', img_len\n",
    "    n = sum([img.shape[1] == img_len for img in images])\n",
    "    X = np.ndarray(shape=(n, img_len))\n",
    "    i = 0\n",
    "    for img in images:\n",
    "        if img.shape[1] == img_len:\n",
    "            X[i,:] = np.array(img)\n",
    "            i += 1\n",
    "    print X.shape\n",
    "    return X, img_len\n",
    "\n",
    "X, img_len = create_tensor(image_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the computations are executed in a backend process. An iPython notebook takes on the role of front-end, the role of the front end is to allow us to write a driver script that creates the computational graph and then runs it in the backend. The common usage pattern is:\n",
    "    1. create a graph\n",
    "    2. launch it in a session.\n",
    "The connection to TensoFlow C++ backend is called a session. \n",
    "\n",
    "But, here we will use InteractiveSession class instead, which allows you to interleave operations which build a computation graph with ones that run the graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception AssertionError: AssertionError() in <bound method InteractiveSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x7f963f4cd7d0>> ignored\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a softmax regression model with a single linear layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholdes (inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_len])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, len(cats)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensors x and y_ are placeholders -- a value that we'll input when we ask TensorFlow to run a computation.\n",
    "The shape argument to placeholder is optional, but it allows TensorFlow to automatically catch bugs stemming from inconsistent tensor shapes.\n",
    "\n",
    "### Variables (intermediate results and outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([img_len, len(cats)]))\n",
    "b = tf.Variable(tf.zeros([len(cats)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted Class and Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiply the vectorized input images x by the weight matrix W, add the bias b, and compute the softmax probabilities that are assigned to each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x,W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that reduce_sum is needed to sum up all the element-wise products of the arrays, these arrays are the size of a batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model, one minibatch at the time.\n",
    " - the batch size is chosen here (50)\n",
    " - feed__dict replaces the placeholder tensors x and y_ with the training examples.\n",
    " \n",
    " Note: feed_dict can replace any tensor in the computation graph -- it's not restricted to just placeholders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 520500)\n",
      "[ 1.  0.]\n",
      "Iteration: 0\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [200,2] vs. [20,2]\n\t [[Node: gradients_8/mul_8_grad/BroadcastGradientArgs = BroadcastGradientArgs[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients_8/mul_8_grad/Shape, gradients_8/mul_8_grad/Shape_1)]]\nCaused by op u'gradients_8/mul_8_grad/BroadcastGradientArgs', defined at:\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/traitlets/config/application.py\", line 589, in launch_instance\n    app.start()\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 405, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 260, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 212, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 370, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 175, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-202-e1b82c8bf059>\", line 1, in <module>\n    train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 186, in minimize\n    aggregation_method=aggregation_method)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 232, in compute_gradients\n    aggregation_method=aggregation_method)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py\", line 445, in gradients\n    in_grads = _AsList(grad_fn(op_wrapper, *out_grads))\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tensorflow/python/ops/math_grad.py\", line 290, in _MulGrad\n    rx, ry = gen_array_ops._broadcast_gradient_args(sx, sy)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 30, in _broadcast_gradient_args\n    name=name)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 664, in apply_op\n    op_def=op_def)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1834, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1043, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op u'mul_8', defined at:\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n[elided 17 identical lines from previous traceback]\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-201-a1ad3731e187>\", line 1, in <module>\n    cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 426, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 728, in mul\n    return _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 664, in apply_op\n    op_def=op_def)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1834, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1043, in __init__\n    self._traceback = _extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-203-60ee9f8747b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;34m'Iteration:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mtrain_step\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m   1323\u001b[0m         \u001b[0mnone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m     \"\"\"\n\u001b[1;32m-> 1325\u001b[1;33m     \u001b[0m_run_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[1;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   2943\u001b[0m                        \u001b[1;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2944\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 2945\u001b[1;33m   \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2946\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munique_fetch_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[1;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, target_list, fetch_list, feed_dict)\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m         raise errors._make_specific_exception(node_def, op, error_message,\n\u001b[1;32m--> 444\u001b[1;33m                                               e.code)\n\u001b[0m\u001b[0;32m    445\u001b[0m         \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_traceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [200,2] vs. [20,2]\n\t [[Node: gradients_8/mul_8_grad/BroadcastGradientArgs = BroadcastGradientArgs[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients_8/mul_8_grad/Shape, gradients_8/mul_8_grad/Shape_1)]]\nCaused by op u'gradients_8/mul_8_grad/BroadcastGradientArgs', defined at:\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/traitlets/config/application.py\", line 589, in launch_instance\n    app.start()\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 405, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 260, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 212, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 370, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 175, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-202-e1b82c8bf059>\", line 1, in <module>\n    train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 186, in minimize\n    aggregation_method=aggregation_method)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 232, in compute_gradients\n    aggregation_method=aggregation_method)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py\", line 445, in gradients\n    in_grads = _AsList(grad_fn(op_wrapper, *out_grads))\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tensorflow/python/ops/math_grad.py\", line 290, in _MulGrad\n    rx, ry = gen_array_ops._broadcast_gradient_args(sx, sy)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 30, in _broadcast_gradient_args\n    name=name)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 664, in apply_op\n    op_def=op_def)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1834, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1043, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op u'mul_8', defined at:\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n[elided 17 identical lines from previous traceback]\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-201-a1ad3731e187>\", line 1, in <module>\n    cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 426, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 728, in mul\n    return _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 664, in apply_op\n    op_def=op_def)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1834, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/adrian/anaconda2/envs/deep/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1043, in __init__\n    self._traceback = _extract_stack()\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "batch_size = 50\n",
    "flat_image_train = []\n",
    "print X.shape\n",
    "print label_train[0]\n",
    "for i in range(50):\n",
    "    if i % 10 == 0:\n",
    "        print 'Iteration:', i \n",
    "    train_step.run(feed_dict={x: X, y_: label_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.argmax gives the index of the highest entry in a tensor along some axis. For example, tf.argmax(y,1) is the label our model thinks is most likely for each input, while tf.argmax(y_,1) is the true label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to determine what fraction of the probabilities match, the first op cast to floating point numbers and then take the mean. For example, [True, False, True, True] would become [1,0,1,1] which would become 0.75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run out accuracy formula on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 393600)\n",
      "Categories:  2\n",
      "Image size: 393600\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (478500) into shape (393600)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-167-cc8b85f6e1db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mXT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mXT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlabel_test\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-159-b95aec7cb2a1>\u001b[0m in \u001b[0;36mcreate_tensor\u001b[1;34m(images, cats)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_len\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (478500) into shape (393600)"
     ]
    }
   ],
   "source": [
    "XT, _ = create_tensor(image_test, cats)\n",
    "print(accuracy.eval(feed_dict={x: XT, y_: label_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Multilayer Convolutional Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to need to create a lot of weights and biases. \n",
    "- Weights are initialized with a small amount of noise for symmetry breaking. \n",
    "- Since we're using ReLU neurons, we chose a slightly positive initial bias to avoid \"dead neurons.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convolution uses a stride of one and are zero padded so that the output is the same size as the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subsampling is max pooling over 2x2 blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convolutional will compute 32 features for each 5x5 patch. \n",
    "\n",
    "The weight tensor will have a shape of [5, 5, 1, 32]. \n",
    "The first two dimensions are the patch size, the next is the number of input channels, and the last is the number of output channels. \n",
    "We will also have a bias vector with a component for each output channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inputs are images of 28x28 pixels flattened to 784 bits, in order to aply the convolutional scan with a scanning window (filter) of 5x5 pixels\n",
    "we need to reshape the flattened array back to its original 2-d bitmap shape. The conv function expects a x in the form of a 4d tensor, with the second and third dimensions corresponding to image width and height, and the final dimension corresponding to the number of color channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1,28,28,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then convolve x_image with the weight tensor,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv = conv2d(x_image, W_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the bias and apply ReLU nonlinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Shape:0\", shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "h_conv1 = tf.nn.relu(conv + b_conv1)\n",
    "print tf.shape(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsampling (2x2 ---> 1x1), this means that the image has been reduced from 28x28 to 14x14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Shape_1:0\", shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "print tf.shape(h_pool1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Convolutional Layer\n",
    "We stack several layers of this type. The second layer will have 64 features for each 5x5 patch.\n",
    "\n",
    "The weight tensor will have a shape of [5, 5, 32, 64]. The first two dimensions are the patch size, the next is the number of input channels (we created 32 channels in the first convolutional layer), and the last is the number of output channels (now we increase it frpom 32 to 64). We will also have a bias vector with a component for each output channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Densely Connected Layer\n",
    "We add a fully-connected layer with 1024 neurons\n",
    "The image size has been reduced to 7x7, and is 64 in depth.\n",
    "To feed the mages into the fully connected layer, we need to flatten them, reshaping each image into a flat vector that is 7x7x64 in length. This give us a batch of vectors.\n",
    "\n",
    "Once the data is in the proper format, we multiply by a weight matrix, the weigth matrix is actually post-multiplying the batch of image flat vectors, the weigth matrix has 7x7x64 rows (one for each pixel in the image) and 1024 columns (one for each neuron in this layer). After postmultiplying the image batch by this weight matrix, we get vectors of size 1024, each vectors represents how a given input image exites each of the 1024 neurons of this layer. To this vectors we add the bias vectors, wich is also 1024.\n",
    "Then we apply a ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_fc1_logits = tf.matmul(h_pool2_flat, W_fc1) + b_fc1\n",
    "\n",
    "h_fc1 = tf.nn.relu(h_fc1_logits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "To reduce overfitting, we will apply dropout before the readout layer. We create a placeholder for the probability that a neuron's output is kept during dropout. This allows us to turn dropout on during training, and turn it off during testing. TensorFlow's tf.nn.dropout op automatically handles scaling neuron outputs in addition to masking them, so dropout just works without any additional scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keep_prob is a boolean vars will be specified when the graph is run\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Readout Layer\n",
    "Finally, we add a softmax layer.\n",
    "Notice that the weight matrix converts from 1024 inputs to 10 outputs, that is, the matrix has 1024 rows and 10 columns, and it post-multiplies the batch of arrays, each of 1024 numbers that comes from the previous layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate the Model\n",
    "How well does this model do? To train and evaluate it we will use code that is nearly identical to that for the simple one layer SoftMax network above. The differences are that: we will replace the steepest gradient descent optimizer with the more sophisticated ADAM optimizer; we will include the additional parameter keep_prob in feed_dict to control the dropout rate; and we will add logging to every 100th iteration in the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the training loop, the saver.save() method will periodically be called to write a checkpoint file to the training directory with the current values of all the trainable variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.1\n",
      "step 20, training accuracy 0.44\n",
      "step 40, training accuracy 0.78\n",
      "step 60, training accuracy 0.74\n",
      "step 80, training accuracy 0.86\n",
      "step 100, training accuracy 0.88\n",
      "step 120, training accuracy 0.92\n",
      "step 140, training accuracy 0.94\n",
      "step 160, training accuracy 0.84\n",
      "step 180, training accuracy 0.96\n",
      "test accuracy 0.9115\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.initialize_all_variables())\n",
    "for i in range(200):\n",
    "  batch = mnist.train.next_batch(50)\n",
    "  if i%20 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "  if i == 100:\n",
    "    saver.save(sess, \"train/mnist-red\", global_step=i)\n",
    "    \n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final test set accuracy after running this code should be approximately 99.2%.\n",
    "I can observe 0.91 after 200 epochs.\n",
    "\n",
    "### Restore all session variables\n",
    "Restore all of session's tensors back to a previous checkpoint.\n",
    "\n",
    "Note that this doesn't changes any o the current Python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.8629\n",
      "199\n"
     ]
    }
   ],
   "source": [
    "saver.restore(sess, \"train/mnist-red-100\")\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "\n",
    "print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
